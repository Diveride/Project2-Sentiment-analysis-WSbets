{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **This is a initial descriptive analysis of the Reddit wallstreetbets posts. It contains a basic statistics of words, character count, and occurence. At the bottom, you will find the analysis of the most common mentioned NYSE or other stock tickers. Enjoy!**"},{"metadata":{},"cell_type":"markdown","source":"**Short summary:**\nThe average title length is 11 words.\nThe average title length is 120 words.\nThe most popular words are, without a surprise: gme, buy, robinhood, hold, amc.\nThe most popular tickers are: gme, know, one, hold, see, time, big, amc"},{"metadata":{},"cell_type":"markdown","source":"# Import the libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport re\nimport nltk\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\n\nfrom datetime import date, datetime\nfrom sklearn import datasets, linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom scipy import stats\nfrom nltk.corpus import stopwords\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/reddit-wallstreetsbets-posts/reddit_wsb.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check the head of the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Drop useless columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(columns=['id', 'url', 'created'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add a few data realted columns for further analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import date, datetime\nyear_col = []\nmonth_col = []\nhour_col = []\nminute_col = []\nfor i, content in df['timestamp'].items():\n    t1 = datetime.strptime(content, '%Y-%m-%d %H:%M:%S')\n    year_col.append(t1.year)\n    month_col.append(t1.month)\n    hour_col.append(t1.hour)\n    minute_col.append(t1.minute)\ndf['year'] = year_col\ndf['month'] = month_col\ndf['hour'] = hour_col\ndf['minute'] = minute_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalize the text to be lowercase"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title'] = df['title'].str.lower()\ndf['body'] = df['body'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop_duplicates(subset=['title'], keep='first', inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Descriptive statistics - title"},{"metadata":{},"cell_type":"markdown","source":"**Count the number of characters and length of a title**"},{"metadata":{"trusted":true},"cell_type":"code","source":"count = df['title'].str.split().str.len()\ncount.index = count.index.astype(str) + ' words:'\ncount.sort_index(inplace=True)\n\nprint(\"Total number of words: \", count.sum(), \"words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average number of words per post: \", round(count.mean(),2), \"words\")\nprint(\"Max number of words per post: \", count.max(), \"words\")\nprint(\"Min number of words per post: \", count.min(), \"words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def word_count(df):\n    \"\"\"\n    This function takes the dataframe and adds a new colun with the number of words.\n    :param df: The dataframe to be transformed.\n    :return: The transformed dataframe.\n    \"\"\"\n    words_count = []\n    for i, content in df['title'].items():\n        new_values =[]\n        new_values = content.split()\n        words_count.append(len(new_values))\n    df['title_word_count'] = words_count\n    return df\n\ndf = word_count(df)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title_length'] = df['title'].str.len()\n\nprint(\"Total length of a dataset: \", df.title_length.sum(), \"characters\")\nprint(\"Average length of a tweet: \", round(df.title_length.mean(),0), \"characters\")\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.heatmap(df.drop(columns=['year']).corr(), annot=True, linewidths=1.5, fmt=\".2f\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Most popular words used in title"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_text_blob(df, text_column):\n    blob_text=[]\n    for i, content in df[text_column].items():\n        for i in content.split():\n            blob_text.append(i.lower())\n    return blob_text\n\nblob_text = create_text_blob(df, 'title')\nprint(blob_text[0:100])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's remove the stop words"},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('stopwords')\nstop_words = set(stopwords.words('english'))  \nfiltered_sentence = [w for w in blob_text if not w in stop_words]  \nfiltered_sentence = []  \n  \nfor w in blob_text:  \n    if w not in stop_words:  \n        filtered_sentence.append(w)  \n\nprint(filtered_sentence[0:100])  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = Counter(filtered_sentence)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's print the most popular words, used over 700 times"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ntop_20_words = {}\n\nfor (key, value) in counts.items():\n   # Check if value is greater than 200 and add to new dictionary\n    if value > 700 :\n        top_20_words[key] = value\n    continue\n\nsorted_top_20_words = dict(sorted(top_20_words.items(), key=lambda item: item[1], reverse=False))\n\nword = sorted_top_20_words.keys()\ncount = sorted_top_20_words.values()\n\n\nfig = px.bar(y=word, x=count, text = count)\nfig.update_traces(texttemplate='%{text:}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_20_words_clean = {}\n\nfor (key, value) in counts.items():\n    # Check if key length is greater than 3 and value greater than 150 and add to new dictionary\n    if len(key)>2 and value > 700 :\n        top_20_words_clean[key] = value\n    continue\n\nsorted_top_20_words_clean = dict(sorted(top_20_words_clean.items(), key=lambda item: item[1], reverse=False))\n\nword = sorted_top_20_words_clean.keys()\ncount = sorted_top_20_words_clean.values()\n\nfig = px.bar(y=word, x=count, text = count)\nfig.update_traces(texttemplate='%{text:}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Descriptive statistics - body"},{"metadata":{"trusted":true},"cell_type":"code","source":"count = df['body'].str.split().str.len()\ncount.index = count.index.astype(str) + ' words:'\ncount.sort_index(inplace=True)\n\nprint(\"Total number of words: \", count.sum(), \"words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average number of words per post: \", round(count.mean(),2), \"words\")\nprint(\"Max number of words per post: \", count.max(), \"words\")\nprint(\"Min number of words per post: \", count.min(), \"words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['body_length'] = df['body'].str.len()\n\nprint(\"Total length of a dataset: \", df.body_length.sum(), \"characters\")\nprint(\"Average length of a tweet: \", round(df.body_length.mean(),0), \"characters\")\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_text_blob(df, text_column):\n    blob_text=[]\n    for i, content in df[text_column].items():\n        for i in str(content).split():\n            blob_text.append(i.lower())\n    return blob_text\n\nblob_text = create_text_blob(df, 'body')\nprint(blob_text[0:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('stopwords')\nstop_words = set(stopwords.words('english'))  \nstop_words.add('nan')\nfiltered_sentence = [w for w in blob_text if not w in stop_words]  \nfiltered_sentence = []  \n  \nfor w in blob_text:  \n    if w not in stop_words:  \n        filtered_sentence.append(w)  \n\nprint(filtered_sentence[0:100])  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts_body = Counter(filtered_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ntop_20_words = {}\n\nfor (key, value) in counts_body.items():\n   # Check if value is greater than 3000 and add to new dictionary\n    if value != \"nan\" and value > 3000:\n        top_20_words[key] = value\n    continue\n\nsorted_top_20_words = dict(sorted(top_20_words.items(), key=lambda item: item[1], reverse=False))\n\nword = sorted_top_20_words.keys()\ncount = sorted_top_20_words.values()\n\n\nfig = px.bar(y=word, x=count, text = count)\nfig.update_traces(texttemplate='%{text:}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Let's see what are the most popular tickers mentioned in the body text**"},{"metadata":{"trusted":true},"cell_type":"code","source":"nyse_tickers = pd.read_csv(\"../input/tickers/nyse-listed_csv.csv\")\nother_tickers = pd.read_csv(\"../input/tickers/other-listed_csv.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nyse_tickers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nyse_tickers_list = list(nyse_tickers['ACT Symbol'].str.lower())\nother_tickers_list = list(other_tickers['ACT Symbol'].str.lower())\nnyse_tickers_list[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ntop_words = {}\n\nfor (key, value) in counts_body.items():\n   # Check if value is greater than 100 and add to new dictionary\n    if key in nyse_tickers_list and value > 300: \n        top_words[key] = value\n    continue\n    \nsorted_top_words = dict(sorted(top_words.items(), key=lambda item: item[1], reverse=False))\n\nword = sorted_top_words.keys()\ncount = sorted_top_words.values()\n\nfig = px.bar(y=word, x=count, text = count, title='Nyse Tickers')\nfig.update_traces(texttemplate='%{text:}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ntop_words = {}\n\nfor (key, value) in counts_body.items():\n   # Check if value is greater than 100 and add to new dictionary\n    if key in other_tickers_list and value > 500: \n        top_words[key] = value\n    continue\n    \nsorted_top_words = dict(sorted(top_words.items(), key=lambda item: item[1], reverse=False))\n\nword = sorted_top_words.keys()\ncount = sorted_top_words.values()\n\nfig = px.bar(y=word, x=count, text = count, title='Other Tickers')\nfig.update_traces(texttemplate='%{text:}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}