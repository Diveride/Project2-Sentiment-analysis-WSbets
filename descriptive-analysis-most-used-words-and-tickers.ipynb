{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **This is a initial descriptive analysis of the Reddit wallstreetbets posts. It contains a basic statistics of words, character count, and occurence. At the bottom, you will find the analysis of the most common mentioned NYSE or other stock tickers. Enjoy!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Short summary:**\n",
    "The average title length is 11 words.\n",
    "The average title length is 120 words.\n",
    "The most popular words are, without a surprise: gme, buy, robinhood, hold, amc.\n",
    "The most popular tickers are: gme, know, one, hold, see, time, big, amc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from datetime import date, datetime\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/reddit-wallstreetsbets-posts/reddit_wsb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the head of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['id', 'url', 'created'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a few data realted columns for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "year_col = []\n",
    "month_col = []\n",
    "hour_col = []\n",
    "minute_col = []\n",
    "for i, content in df['timestamp'].items():\n",
    "    t1 = datetime.strptime(content, '%Y-%m-%d %H:%M:%S')\n",
    "    year_col.append(t1.year)\n",
    "    month_col.append(t1.month)\n",
    "    hour_col.append(t1.hour)\n",
    "    minute_col.append(t1.minute)\n",
    "df['year'] = year_col\n",
    "df['month'] = month_col\n",
    "df['hour'] = hour_col\n",
    "df['minute'] = minute_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the text to be lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].str.lower()\n",
    "df['body'] = df['body'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['title'], keep='first', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics - title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of characters and length of a title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df['title'].str.split().str.len()\n",
    "count.index = count.index.astype(str) + ' words:'\n",
    "count.sort_index(inplace=True)\n",
    "\n",
    "print(\"Total number of words: \", count.sum(), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average number of words per post: \", round(count.mean(),2), \"words\")\n",
    "print(\"Max number of words per post: \", count.max(), \"words\")\n",
    "print(\"Min number of words per post: \", count.min(), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(df):\n",
    "    \"\"\"\n",
    "    This function takes the dataframe and adds a new colun with the number of words.\n",
    "    :param df: The dataframe to be transformed.\n",
    "    :return: The transformed dataframe.\n",
    "    \"\"\"\n",
    "    words_count = []\n",
    "    for i, content in df['title'].items():\n",
    "        new_values =[]\n",
    "        new_values = content.split()\n",
    "        words_count.append(len(new_values))\n",
    "    df['title_word_count'] = words_count\n",
    "    return df\n",
    "\n",
    "df = word_count(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_length'] = df['title'].str.len()\n",
    "\n",
    "print(\"Total length of a dataset: \", df.title_length.sum(), \"characters\")\n",
    "print(\"Average length of a tweet: \", round(df.title_length.mean(),0), \"characters\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(df.drop(columns=['year']).corr(), annot=True, linewidths=1.5, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most popular words used in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_blob(df, text_column):\n",
    "    blob_text=[]\n",
    "    for i, content in df[text_column].items():\n",
    "        for i in content.split():\n",
    "            blob_text.append(i.lower())\n",
    "    return blob_text\n",
    "\n",
    "blob_text = create_text_blob(df, 'title')\n",
    "print(blob_text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's remove the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))  \n",
    "filtered_sentence = [w for w in blob_text if not w in stop_words]  \n",
    "filtered_sentence = []  \n",
    "  \n",
    "for w in blob_text:  \n",
    "    if w not in stop_words:  \n",
    "        filtered_sentence.append(w)  \n",
    "\n",
    "print(filtered_sentence[0:100])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's print the most popular words, used over 700 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "top_20_words = {}\n",
    "\n",
    "for (key, value) in counts.items():\n",
    "   # Check if value is greater than 200 and add to new dictionary\n",
    "    if value > 700 :\n",
    "        top_20_words[key] = value\n",
    "    continue\n",
    "\n",
    "sorted_top_20_words = dict(sorted(top_20_words.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "word = sorted_top_20_words.keys()\n",
    "count = sorted_top_20_words.values()\n",
    "\n",
    "\n",
    "fig = px.bar(y=word, x=count, text = count)\n",
    "fig.update_traces(texttemplate='%{text:}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_words_clean = {}\n",
    "\n",
    "for (key, value) in counts.items():\n",
    "    # Check if key length is greater than 3 and value greater than 150 and add to new dictionary\n",
    "    if len(key)>2 and value > 700 :\n",
    "        top_20_words_clean[key] = value\n",
    "    continue\n",
    "\n",
    "sorted_top_20_words_clean = dict(sorted(top_20_words_clean.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "word = sorted_top_20_words_clean.keys()\n",
    "count = sorted_top_20_words_clean.values()\n",
    "\n",
    "fig = px.bar(y=word, x=count, text = count)\n",
    "fig.update_traces(texttemplate='%{text:}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics - body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df['body'].str.split().str.len()\n",
    "count.index = count.index.astype(str) + ' words:'\n",
    "count.sort_index(inplace=True)\n",
    "\n",
    "print(\"Total number of words: \", count.sum(), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average number of words per post: \", round(count.mean(),2), \"words\")\n",
    "print(\"Max number of words per post: \", count.max(), \"words\")\n",
    "print(\"Min number of words per post: \", count.min(), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_length'] = df['body'].str.len()\n",
    "\n",
    "print(\"Total length of a dataset: \", df.body_length.sum(), \"characters\")\n",
    "print(\"Average length of a tweet: \", round(df.body_length.mean(),0), \"characters\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_blob(df, text_column):\n",
    "    blob_text=[]\n",
    "    for i, content in df[text_column].items():\n",
    "        for i in str(content).split():\n",
    "            blob_text.append(i.lower())\n",
    "    return blob_text\n",
    "\n",
    "blob_text = create_text_blob(df, 'body')\n",
    "print(blob_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))  \n",
    "stop_words.add('nan')\n",
    "filtered_sentence = [w for w in blob_text if not w in stop_words]  \n",
    "filtered_sentence = []  \n",
    "  \n",
    "for w in blob_text:  \n",
    "    if w not in stop_words:  \n",
    "        filtered_sentence.append(w)  \n",
    "\n",
    "print(filtered_sentence[0:100])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_body = Counter(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "top_20_words = {}\n",
    "\n",
    "for (key, value) in counts_body.items():\n",
    "   # Check if value is greater than 3000 and add to new dictionary\n",
    "    if value != \"nan\" and value > 3000:\n",
    "        top_20_words[key] = value\n",
    "    continue\n",
    "\n",
    "sorted_top_20_words = dict(sorted(top_20_words.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "word = sorted_top_20_words.keys()\n",
    "count = sorted_top_20_words.values()\n",
    "\n",
    "\n",
    "fig = px.bar(y=word, x=count, text = count)\n",
    "fig.update_traces(texttemplate='%{text:}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Let's see what are the most popular tickers mentioned in the body text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_tickers = pd.read_csv(\"../input/tickers/nyse-listed_csv.csv\")\n",
    "other_tickers = pd.read_csv(\"../input/tickers/other-listed_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_tickers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_tickers_list = list(nyse_tickers['ACT Symbol'].str.lower())\n",
    "other_tickers_list = list(other_tickers['ACT Symbol'].str.lower())\n",
    "nyse_tickers_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "top_words = {}\n",
    "\n",
    "for (key, value) in counts_body.items():\n",
    "   # Check if value is greater than 100 and add to new dictionary\n",
    "    if key in nyse_tickers_list and value > 300: \n",
    "        top_words[key] = value\n",
    "    continue\n",
    "    \n",
    "sorted_top_words = dict(sorted(top_words.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "word = sorted_top_words.keys()\n",
    "count = sorted_top_words.values()\n",
    "\n",
    "fig = px.bar(y=word, x=count, text = count, title='Nyse Tickers')\n",
    "fig.update_traces(texttemplate='%{text:}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "top_words = {}\n",
    "\n",
    "for (key, value) in counts_body.items():\n",
    "   # Check if value is greater than 100 and add to new dictionary\n",
    "    if key in other_tickers_list and value > 500: \n",
    "        top_words[key] = value\n",
    "    continue\n",
    "    \n",
    "sorted_top_words = dict(sorted(top_words.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "word = sorted_top_words.keys()\n",
    "count = sorted_top_words.values()\n",
    "\n",
    "fig = px.bar(y=word, x=count, text = count, title='Other Tickers')\n",
    "fig.update_traces(texttemplate='%{text:}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
